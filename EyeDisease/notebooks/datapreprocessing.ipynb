{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11f8c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m graycomatrix, graycoprops\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "# from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fec6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_image(file_path):\n",
    "    try:\n",
    "        with Image.open(file_path) as img:\n",
    "            img.verify()  # Verify that it is an image\n",
    "        return True\n",
    "    except (IOError, SyntaxError):\n",
    "        return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a452c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = \"../dataset\"\n",
    "corrupted_images = []\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_directory):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            file_path = os.path.join(root, file)\n",
    "            if not is_valid_image(file_path):\n",
    "                corrupted_images.append(file_path)\n",
    "\n",
    "if corrupted_images:\n",
    "    print(\"Corrupted images found:\")\n",
    "    for img in corrupted_images:\n",
    "        print(img)\n",
    "else:\n",
    "    print(\"No corrupted images found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b608233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing and Normalizing the dataset\n",
    "\n",
    "TARGET_SIZE = (224, 224)\n",
    "\n",
    "def preprocess_image(file_path, save_dir):\n",
    "    try:\n",
    "        with Image.open(file_path) as img:\n",
    "            img = img.convert('RGB')  # Ensure 3 color channels\n",
    "            img = img.resize(TARGET_SIZE)  # Resize\n",
    "            \n",
    "            # Normalize: convert to array and divide by 255\n",
    "            img_array = np.array(img) / 255.0\n",
    "            \n",
    "            # Optional: Save preprocessed image (remove this if just using in memory)\n",
    "            save_path = os.path.join(save_dir, os.path.basename(file_path))\n",
    "            img.save(save_path)\n",
    "\n",
    "            return img_array  # Return array if needed for model\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying to all images\n",
    "\n",
    "input_directory = \"../dataset/train\"\n",
    "output_directory = \"../processed_dataset/train\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "for root, dirs, files in os.walk(input_directory):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            file_path = os.path.join(root, file)\n",
    "            if is_valid_image(file_path):\n",
    "                preprocess_image(file_path, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = '../dataset'\n",
    "\n",
    "classes = os.listdir(dataset_path)\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "for cls in classes:\n",
    "    class_path = os.path.join(dataset_path, cls)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    print(f\"Class: {cls} - Number of images: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733622a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual Inspection of the dataset, to make sure i'm actually working with data\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "fig, axs = plt.subplots(1, len(classes), figsize=(15,5))\n",
    "\n",
    "for i, cls in enumerate(classes):\n",
    "    class_path = os.path.join(dataset_path, cls)\n",
    "    img_name = os.listdir(class_path)[0]  # Just take the first image\n",
    "    img = Image.open(os.path.join(class_path, img_name))\n",
    "    img = img.resize((100, 100))\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set_title(cls)\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction function\n",
    "\n",
    "def extract_image_features(img_array, num_bins=10):\n",
    "    \"\"\"\n",
    "    Extract average brightness and color histogram from an image array.\n",
    "    \n",
    "    Parameters:\n",
    "        img_array: numpy array of shape (224, 224, 3)\n",
    "        num_bins: number of bins for histogram\n",
    "\n",
    "    Returns:\n",
    "        avg_brightness: float\n",
    "        hist_features: list of floats (flattened histogram)\n",
    "    \"\"\"\n",
    "    # Average brightness: mean of all channels\n",
    "    avg_brightness = np.mean(img_array)\n",
    "\n",
    "    # Histogram: calculate for each channel separately\n",
    "    hist_r, _ = np.histogram(img_array[:, :, 0], bins=num_bins, range=(0, 1), density=True)\n",
    "    hist_g, _ = np.histogram(img_array[:, :, 1], bins=num_bins, range=(0, 1), density=True)\n",
    "    hist_b, _ = np.histogram(img_array[:, :, 2], bins=num_bins, range=(0, 1), density=True)\n",
    "\n",
    "    # Combine all histograms into one flat list\n",
    "    hist_features = np.concatenate([hist_r, hist_g, hist_b]).tolist()\n",
    "\n",
    "    return avg_brightness, hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6bfa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../dataset'\n",
    "img_size = 224\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for label in os.listdir(data_dir):\n",
    "    folder_path = os.path.join(data_dir, label)\n",
    "    \n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue  # Skip if not a folder\n",
    "    \n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        \n",
    "        # Read and preprocess image\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue  # Skip unreadable images\n",
    "        \n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        img = img / 255.0  # normalize\n",
    "        \n",
    "        # Append image and label\n",
    "        X.append(img)\n",
    "        y.append(label)  # the folder name is the class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93959a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_additional_features = []\n",
    "\n",
    "for img in X:\n",
    "    avg_brightness, hist_features = extract_image_features(img)\n",
    "    # Combine into one flat feature vector (brightness + histogram)\n",
    "    combined_features = [avg_brightness] + hist_features\n",
    "    X_additional_features.append(combined_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2559ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(y)\n",
    "# Just to make sure the data is in the right format\n",
    "print(\"Number of images:\", len(X))\n",
    "print(\"Number of classes:\", len(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab55a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_additional_features = np.array(X_additional_features)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd813785",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../dataset'\n",
    "img_size = 224\n",
    "\n",
    "X_images = []\n",
    "X_features = []\n",
    "y_labels = []\n",
    "\n",
    "def extract_features(img_array, num_bins=10):\n",
    "    avg_brightness = np.mean(img_array)\n",
    "    \n",
    "    hist_r, _ = np.histogram(img_array[:, :, 0], bins=num_bins, range=(0, 1), density=True)\n",
    "    hist_g, _ = np.histogram(img_array[:, :, 1], bins=num_bins, range=(0, 1), density=True)\n",
    "    hist_b, _ = np.histogram(img_array[:, :, 2], bins=num_bins, range=(0, 1), density=True)\n",
    "    \n",
    "    hist_features = np.concatenate([hist_r, hist_g, hist_b]).tolist()\n",
    "    return avg_brightness, hist_features\n",
    "\n",
    "# Load images + extract features\n",
    "for label in os.listdir(data_dir):\n",
    "    folder_path = os.path.join(data_dir, label)\n",
    "    \n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    \n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        img = img / 255.0\n",
    "        \n",
    "        # Store image\n",
    "        X_images.append(img)\n",
    "        y_labels.append(label)\n",
    "        \n",
    "        # Extract features\n",
    "        avg_brightness, hist_features = extract_features(img)\n",
    "        combined_features = [avg_brightness] + hist_features\n",
    "        X_features.append(combined_features)\n",
    "\n",
    "# Convert to arrays\n",
    "X_features = np.array(X_features)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a65b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average brightness distribution\n",
    "\n",
    "avg_brightness_values = [f[0] for f in X_features]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(avg_brightness_values, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Average Brightness')\n",
    "plt.xlabel('Average Brightness')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of first image\n",
    "hist_features_sample = X_features[0][1:]  # skip avg_brightness\n",
    "bins = np.linspace(0, 1, 11)  # 10 bins â†’ 11 edges\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(bins[:-1], hist_features_sample[:10], label='Red', color='r')\n",
    "plt.plot(bins[:-1], hist_features_sample[10:20], label='Green', color='g')\n",
    "plt.plot(bins[:-1], hist_features_sample[20:], label='Blue', color='b')\n",
    "plt.legend()\n",
    "plt.title('Color Histogram (Sample Image)')\n",
    "plt.xlabel('Pixel Intensity (Normalized)')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e126265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Convolutional Neural Network (CNN) model\n",
    "\n",
    "#Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a49bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale pixel values\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Training generator\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    '../dataset',\n",
    "    target_size=(128, 128),      # You can increase this later\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Validation generator\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    '../dataset',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')  # 4 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd183e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0641a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient Eye Mapping System\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def extract_eye_info(filename):\n",
    "    \"\"\"Extract patient ID and eye side from filename\"\"\"\n",
    "    # Handle different naming patterns\n",
    "    if '-' in filename:\n",
    "        base, side = filename.rsplit('-', 1)\n",
    "        side = side.split('.')[0].lower()\n",
    "        return base, side\n",
    "    elif '_' in filename:\n",
    "        base, side = filename.rsplit('_', 1)\n",
    "        side = side.split('.')[0].lower()\n",
    "        return base, side\n",
    "    else:\n",
    "        # Extract numeric patient ID if exists\n",
    "        match = re.search(r'(\\d+)', filename)\n",
    "        patient_id = match.group(1) if match else filename.split('.')[0]\n",
    "        return patient_id, 'unknown'\n",
    "\n",
    "# Create metadata dataframe\n",
    "eye_metadata = []\n",
    "for class_name in os.listdir(dataset_directory):\n",
    "    class_path = os.path.join(dataset_directory, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "        \n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        patient_id, eye_side = extract_eye_info(img_name)\n",
    "        \n",
    "        eye_metadata.append({\n",
    "            'patient_id': patient_id,\n",
    "            'eye_side': eye_side,\n",
    "            'class': class_name,\n",
    "            'path': img_path\n",
    "        })\n",
    "\n",
    "df_eyes = pd.DataFrame(eye_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b12f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize images based on labeling\n",
    "def categorize_eye(row):\n",
    "    if row['eye_side'] in ['left', 'right']:\n",
    "        return 'labeled'\n",
    "    elif row['eye_side'] == 'unknown':\n",
    "        return 'unlabeled'\n",
    "    else:\n",
    "        return 'ambiguous'\n",
    "\n",
    "df_eyes['label_status'] = df_eyes.apply(categorize_eye, axis=1)\n",
    "\n",
    "# Strategy for each category:\n",
    "# 1. Labeled: Use in pairs where possible\n",
    "# 2. Unlabeled: Treat as standalone images\n",
    "# 3. Ambiguous: Flag for manual review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1946a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_groups = []\n",
    "for (patient_id, class_name), group in df_eyes.groupby(['patient_id', 'class']):\n",
    "    # Identify known pairs\n",
    "    left = group[group['eye_side'] == 'left']\n",
    "    right = group[group['eye_side'] == 'right']\n",
    "    unlabeled = group[group['label_status'] == 'unlabeled']\n",
    "    \n",
    "    # Case 1: Complete pair\n",
    "    if not left.empty and not right.empty:\n",
    "        patient_groups.append({\n",
    "            'patient_id': patient_id,\n",
    "            'class': class_name,\n",
    "            'pair_status': 'complete',\n",
    "            'left_path': left['path'].iloc[0],\n",
    "            'right_path': right['path'].iloc[0]\n",
    "        })\n",
    "    \n",
    "    # Case 2: Single labeled eye + unlabeled eyes\n",
    "    elif not left.empty or not right.empty:\n",
    "        labeled_path = left['path'].iloc[0] if not left.empty else right['path'].iloc[0]\n",
    "        # Create pseudo-pairs with unlabeled images\n",
    "        for _, unlabeled_row in unlabeled.iterrows():\n",
    "            patient_groups.append({\n",
    "                'patient_id': f\"{patient_id}_{unlabeled_row.name}\",\n",
    "                'class': class_name,\n",
    "                'pair_status': 'pseudo_pair',\n",
    "                'left_path': labeled_path,\n",
    "                'right_path': unlabeled_row['path']\n",
    "            })\n",
    "    \n",
    "    # Case 3: Only unlabeled eyes\n",
    "    elif not unlabeled.empty:\n",
    "        # Create all possible pairs from unlabeled eyes\n",
    "        unlabeled_paths = unlabeled['path'].tolist()\n",
    "        for i in range(0, len(unlabeled_paths), 2):\n",
    "            if i+1 < len(unlabeled_paths):\n",
    "                patient_groups.append({\n",
    "                    'patient_id': f\"{patient_id}_pair{i//2}\",\n",
    "                    'class': class_name,\n",
    "                    'pair_status': 'unlabeled_pair',\n",
    "                    'left_path': unlabeled_paths[i],\n",
    "                    'right_path': unlabeled_paths[i+1]\n",
    "                })\n",
    "            else:  # Single unlabeled eye\n",
    "                patient_groups.append({\n",
    "                    'patient_id': f\"{patient_id}_single\",\n",
    "                    'class': class_name,\n",
    "                    'pair_status': 'single_unlabeled',\n",
    "                    'left_path': unlabeled_paths[i],\n",
    "                    'right_path': unlabeled_paths[i]  # Duplicate\n",
    "                })\n",
    "\n",
    "df_pairs = pd.DataFrame(patient_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073588ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class EyePairGenerator(Sequence):\n",
    "    def __init__(self, df_pairs, classes, class_to_index, batch_size=32, \n",
    "                 target_size=(128,128), weight_map=None):\n",
    "        \"\"\"\n",
    "        df_pairs: DataFrame containing the pairs information\n",
    "        classes: List of class names\n",
    "        class_to_index: Dictionary mapping class name to index\n",
    "        batch_size: Number of samples per batch\n",
    "        target_size: Target size for images\n",
    "        weight_map: Dictionary mapping pair_status to weight (optional)\n",
    "        \"\"\"\n",
    "        self.df = df_pairs\n",
    "        self.classes = classes\n",
    "        self.class_to_index = class_to_index\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.weight_map = weight_map\n",
    "        self.indices = np.arange(len(df_pairs))\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        batch_weights = []\n",
    "        \n",
    "        for idx in batch_indices:\n",
    "            row = self.df.iloc[idx]\n",
    "            \n",
    "            # Load and preprocess left eye\n",
    "            left_img = self.load_preprocess(row['left_path'])\n",
    "            \n",
    "            # Load and preprocess right eye\n",
    "            right_img = self.load_preprocess(row['right_path'])\n",
    "            \n",
    "            # Combine into 6-channel image\n",
    "            combined = np.concatenate([left_img, right_img], axis=-1)\n",
    "            batch_images.append(combined)\n",
    "            \n",
    "            # Convert class to one-hot encoding\n",
    "            label = np.zeros(len(self.classes))\n",
    "            label[self.class_to_index[row['class']]] = 1\n",
    "            batch_labels.append(label)\n",
    "            \n",
    "            # Calculate weight based on pair status\n",
    "            weight = self.calculate_weight(row['pair_status'])\n",
    "            batch_weights.append(weight)\n",
    "            \n",
    "        return np.array(batch_images), np.array(batch_labels), np.array(batch_weights)\n",
    "    \n",
    "    def load_preprocess(self, path):\n",
    "        \"\"\"Load and preprocess an image\"\"\"\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            # Create blank image if file can't be read\n",
    "            img = np.zeros((*self.target_size, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = cv2.resize(img, self.target_size)\n",
    "        return img / 255.0  # Normalize\n",
    "    \n",
    "    def calculate_weight(self, pair_status):\n",
    "        \"\"\"Assign weights based on pair reliability\"\"\"\n",
    "        if self.weight_map is None:\n",
    "            return 1.0  # Default weight if no weight_map provided\n",
    "        return self.weight_map.get(pair_status, 0.6)  # Default to 0.6 for unknown status\n",
    "    \n",
    "    def get_all_labels(self):\n",
    "        \"\"\"Get all labels in the dataset (for evaluation)\"\"\"\n",
    "        labels = []\n",
    "        for i in range(len(self.df)):\n",
    "            row = self.df.iloc[i]\n",
    "            label = np.zeros(len(self.classes))\n",
    "            label[self.class_to_index[row['class']]] = 1\n",
    "            labels.append(label)\n",
    "        return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fea4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, Dense\n",
    "from tensorflow.keras.layers import Flatten, Dropout, Multiply, GlobalAveragePooling2D, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_adaptive_siamese(input_shape, num_classes):\n",
    "    # Input layer\n",
    "    img_input = Input(shape=input_shape)\n",
    "    \n",
    "    # Split into eye streams\n",
    "    left_eye = Lambda(lambda x: x[..., :3])(img_input)\n",
    "    right_eye = Lambda(lambda x: x[..., 3:])(img_input)\n",
    "    \n",
    "    # Shared convolutional base\n",
    "    conv_base = tf.keras.Sequential([\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(128, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        GlobalAveragePooling2D()\n",
    "    ])\n",
    "    \n",
    "    # Process each eye\n",
    "    left_features = conv_base(left_eye)\n",
    "    right_features = conv_base(right_eye)\n",
    "    \n",
    "    # Attention mechanism for pair reliability\n",
    "    difference = Lambda(lambda x: tf.abs(x[0] - x[1]))([left_features, right_features])\n",
    "    reliability = Dense(128, activation='sigmoid')(difference)\n",
    "    \n",
    "    # Weight features by reliability\n",
    "    weighted_left = Multiply()([left_features, reliability])\n",
    "    weighted_right = Multiply()([right_features, reliability])\n",
    "    \n",
    "    # Combine features\n",
    "    combined = Concatenate()([weighted_left, weighted_right])\n",
    "    \n",
    "    # Classification head\n",
    "    x = Dense(128, activation='relu')(combined)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs=img_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e70547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_loss(y_true, y_pred):\n",
    "    # Standard categorical crossentropy\n",
    "    base_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Get metadata from generator\n",
    "    pair_status = tf.cast(batch_metadata['pair_status'], tf.float32)\n",
    "    is_same_eye = tf.cast(batch_metadata['is_same_eye'], tf.float32)\n",
    "    \n",
    "    # Weight losses differently\n",
    "    weights = tf.where(\n",
    "        pair_status == 'complete', 1.0,  # Full weight for complete pairs\n",
    "        tf.where(\n",
    "            pair_status == 'pseudo_pair', 0.8,  # Slightly reduced\n",
    "            tf.where(\n",
    "                pair_status == 'unlabeled_pair', 0.7,  # Further reduced\n",
    "                0.5  # Single eyes\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Downweight identical eye pairs\n",
    "    weights = weights * (1.0 - 0.3 * is_same_eye)\n",
    "    \n",
    "    return tf.reduce_mean(base_loss * weights)\n",
    "\n",
    "# Compile model\n",
    "# Use standard loss since weighting is handled in generator\n",
    "model = create_adaptive_siamese((128, 128, 6), len(classes))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1555e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pair_types(df_pairs):\n",
    "    pair_types = ['complete', 'pseudo_pair', 'unlabeled_pair', 'single_unlabeled']\n",
    "    \n",
    "    # Filter out pair types that have no samples\n",
    "    valid_pair_types = [t for t in pair_types if t in df_pairs['pair_status'].unique()]\n",
    "    \n",
    "    # Create subplots based on number of valid pair types\n",
    "    fig, axs = plt.subplots(1, len(valid_pair_types), figsize=(5*len(valid_pair_types), 5))\n",
    "    if len(valid_pair_types) == 0:\n",
    "        print(\"No valid pair types to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Handle single plot case\n",
    "    if len(valid_pair_types) == 1:\n",
    "        axs = [axs]\n",
    "    \n",
    "    # Plot each valid pair type\n",
    "    for i, pair_type in enumerate(valid_pair_types):\n",
    "        ax = axs[i]\n",
    "        sample = df_pairs[df_pairs['pair_status'] == pair_type].sample(1).iloc[0]\n",
    "        \n",
    "        # Load and process images\n",
    "        left_img = cv2.cvtColor(cv2.imread(sample['left_path']), cv2.COLOR_BGR2RGB)\n",
    "        right_img = cv2.cvtColor(cv2.imread(sample['right_path']), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display images side by side\n",
    "        ax.imshow(np.hstack([left_img, right_img]))\n",
    "        ax.set_title(f\"{pair_type.replace('_', ' ').title()}\\n\"\n",
    "                     f\"Patient: {sample['patient_id']}, Class: {sample['class']}\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pair_type_examples.jpg', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6102a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pair_types(df_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 1. Define your classes and class mapping\n",
    "classes = sorted(df_eyes['class'].unique())\n",
    "class_to_index = {cls: i for i, cls in enumerate(classes)}\n",
    "\n",
    "# 2. Create the pairs DataFrame (from previous steps)\n",
    "# Make sure you have df_pairs created from earlier code\n",
    "\n",
    "# 3. Create train/test split by PATIENT ID\n",
    "patient_ids = df_pairs['patient_id'].unique()\n",
    "train_patients, test_patients = train_test_split(patient_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = df_pairs[df_pairs['patient_id'].isin(train_patients)]\n",
    "test_df = df_pairs[df_pairs['patient_id'].isin(test_patients)]\n",
    "\n",
    "# 4. Define weight mapping\n",
    "weight_map = {\n",
    "    'complete': 1.0,\n",
    "    'pseudo_pair': 0.8,\n",
    "    'unlabeled_pair': 0.7,\n",
    "    'single_unlabeled': 0.5\n",
    "}\n",
    "\n",
    "# 5. Create generators\n",
    "train_gen = EyePairGenerator(\n",
    "    train_df, \n",
    "    classes=classes, \n",
    "    class_to_index=class_to_index,\n",
    "    batch_size=16,\n",
    "    target_size=(128, 128),\n",
    "    weight_map=weight_map\n",
    ")\n",
    "\n",
    "# 6. Create the TEST generator (this was missing)\n",
    "test_gen = EyePairGenerator(\n",
    "    test_df, \n",
    "    classes=classes, \n",
    "    class_to_index=class_to_index,\n",
    "    batch_size=16,\n",
    "    target_size=(128, 128),\n",
    "    weight_map=None  # No weighting for validation\n",
    ")\n",
    "\n",
    "# Now you can use both in model.fit()\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=test_gen,  # Now test_gen is defined\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70720711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_gen)\n",
    "print(f\"\\nTest accuracy: {test_acc:.4f}, Test loss: {test_loss:.4f}\")\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(test_gen)\n",
    "y_true = test_gen.get_all_labels()  # You'll need to implement this in your generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert predictions to class indices\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_true, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=classes))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9def5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39763f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to test_df\n",
    "test_df['prediction'] = [classes[i] for i in y_pred_classes]\n",
    "test_df['correct'] = test_df['class'] == test_df['prediction']\n",
    "\n",
    "# Calculate accuracy by pair status\n",
    "pair_accuracy = test_df.groupby('pair_status')['correct'].mean()\n",
    "print(\"\\nAccuracy by Pair Type:\")\n",
    "print(pair_accuracy)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "pair_accuracy.plot(kind='bar', color='skyblue')\n",
    "plt.title('Accuracy by Pair Type')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig('accuracy_by_pair_type.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eye Asymmetry Visualization Function\n",
    "def plot_eye_asymmetry(patient_id, class_name):\n",
    "    # Find the patient's images\n",
    "    patient_eyes = df_eyes[(df_eyes['patient_id'] == patient_id) & \n",
    "                          (df_eyes['class'] == class_name)]\n",
    "    \n",
    "    if len(patient_eyes) == 0:\n",
    "        print(f\"No images found for patient {patient_id} with class {class_name}\")\n",
    "        return\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Load and process images\n",
    "    images = []\n",
    "    sides = []\n",
    "    for _, row in patient_eyes.iterrows():\n",
    "        img = cv2.imread(row['path'])\n",
    "        if img is None:\n",
    "            print(f\"Could not load image: {row['path']}\")\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        images.append(img)\n",
    "        sides.append(row['eye_side'])\n",
    "    \n",
    "    # Display available eyes\n",
    "    for i, (img, side) in enumerate(zip(images, sides)):\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].set_title(f\"{side.capitalize()} Eye\")\n",
    "        axs[i].axis('off')\n",
    "    \n",
    "    # Show difference if both eyes available\n",
    "    if len(images) >= 2:\n",
    "        diff = cv2.absdiff(images[0], images[1])\n",
    "        axs[2].imshow(diff)\n",
    "        axs[2].set_title(\"Absolute Difference\")\n",
    "        axs[2].axis('off')\n",
    "        plt.suptitle(f\"Patient {patient_id} - {class_name}\", fontsize=16)\n",
    "    else:\n",
    "        plt.suptitle(f\"Patient {patient_id} - {class_name} (Only {len(images)} eye available)\", fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'asymmetry_{patient_id}_{class_name}.jpg', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c4cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Visualization Function\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
    "    # Create model that maps input to activations of last conv layer + predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], \n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    # Compute gradient of top predicted class for input image\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, np.argmax(predictions[0])]\n",
    "    \n",
    "    # Compute gradients\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    \n",
    "    # Pool gradients and generate heatmap\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    \n",
    "    return heatmap[0]\n",
    "\n",
    "def visualize_attention(patient_id, class_name, model):\n",
    "    # Find the patient's images\n",
    "    patient_eyes = df_eyes[(df_eyes['patient_id'] == patient_id) & \n",
    "                          (df_eyes['class'] == class_name)]\n",
    "    \n",
    "    if len(patient_eyes) == 0:\n",
    "        print(f\"No images found for patient {patient_id} with class {class_name}\")\n",
    "        return\n",
    "    \n",
    "    # Load and preprocess images\n",
    "    eye_images = []\n",
    "    for _, row in patient_eyes.iterrows():\n",
    "        img = cv2.imread(row['path'])\n",
    "        if img is None:\n",
    "            print(f\"Could not load image: {row['path']}\")\n",
    "            continue\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        img = img / 255.0\n",
    "        eye_images.append(img)\n",
    "    \n",
    "    # If less than 2 eyes, duplicate to make pair\n",
    "    if len(eye_images) == 0:\n",
    "        print(\"No valid images to process\")\n",
    "        return\n",
    "    elif len(eye_images) == 1:\n",
    "        eye_images.append(eye_images[0])\n",
    "    \n",
    "    # Combine into 6-channel image\n",
    "    combined = np.concatenate(eye_images, axis=-1)\n",
    "    combined_batch = np.expand_dims(combined, axis=0)\n",
    "    \n",
    "    # Generate heatmap\n",
    "    try:\n",
    "        heatmap = make_gradcam_heatmap(\n",
    "            combined_batch, \n",
    "            model, \n",
    "            'conv2d_2'  # Update this to your last conv layer name\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"Error generating heatmap: {e}\")\n",
    "        print(\"Check that the last_conv_layer_name exists in your model\")\n",
    "        return\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Left eye\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv2.cvtColor(eye_images[0], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Left Eye\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Right eye\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(cv2.cvtColor(eye_images[1], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Right Eye\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Attention heatmap\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(heatmap, cmap='viridis')\n",
    "    plt.title(\"Attention Heatmap\")\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.suptitle(f\"Patient {patient_id} - {class_name}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'attention_{patient_id}_{class_name}.jpg', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c667a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize eye asymmetry\n",
    "plot_eye_asymmetry(patient_id='1000', class_name='Cataract')\n",
    "\n",
    "# Visualize attention maps\n",
    "visualize_attention(patient_id='1000', class_name='Cataract', model=model)\n",
    "\n",
    "# Visualize pair types\n",
    "visualize_pair_types(df_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf256c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "model.save('eye_disease_model.keras')\n",
    "\n",
    "# Save model weights\n",
    "model.save_weights('model_weights.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7935d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=test_gen,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Training Accuracy:\", history.history['accuracy'][-1])\n",
    "print(\"Final Validation Accuracy:\", history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6625ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_histogram_features(image_array):\n",
    "    \"\"\"Extract color histogram features from image\"\"\"\n",
    "    hist_r = cv2.calcHist([image_array], [0], None, [256], [0, 256]).flatten()\n",
    "    hist_g = cv.calcHist([image_array], [1], None, [256], [0, 256]).flatten()\n",
    "    hist_b = cv.calcHist([image_array], [2], None, [256], [0, 256]).flatten()\n",
    "    return np.concatenate((hist_r, hist_g, hist_b))\n",
    "\n",
    "def extract_edges(image_array):\n",
    "    \"\"\"Extract edge features using Canny edge detection\"\"\"\n",
    "    gray = cv2.cvtColor((image_array * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    return edges.flatten()\n",
    "\n",
    "def extract_texture_features(image_array):\n",
    "    \"\"\"Extract texture features using GLCM\"\"\"\n",
    "    gray = cv2.cvtColor((image_array * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    glcm = greycomatrix(gray, [1], [0], levels=256, symmetric=True, normed=True)\n",
    "    return greycoprops(glcm, 'contrast').flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
